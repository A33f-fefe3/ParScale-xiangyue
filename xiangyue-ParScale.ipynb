{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ff29e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮你的吗？😊\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"0\", base_url=\"http://192.168.106.26:20000/v1\")\n",
    "\n",
    "def llm_qwen(prompt, model=\"Qwen3\", temperature=0.7, top_p=0.8, max_tokens=2048, presence_penalty=1.5):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens,\n",
    "        presence_penalty=presence_penalty,\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm_output = llm_qwen(\"你好\")\n",
    "    print(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6777fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 各视角分析结果 ===\n",
      "视角1 temp=0.20\n",
      "  {\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡到货后一直没信号，之前联系客服被要求再充值30元，但目前只有30元话费，用户认为购买卡的30元应该作为预存话费，但实际只有30元是充值的，存在疑问和不满。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的30元是否会被作为预存话费使用，以及当前话费金额是否合理，同时希望得到明确的解释和解决方案。\",\n",
      "  \"cons_progress\": \"客服首先询问用户提供的号码和订单编号，确认用户通过小程序购买，随后查询发现话费余额为30元，解释为订单内的30元已激活充值。用户表示不理解，客服尝试转接省内客服核实，但用户未提供姓名和手机号，客服要求用户提供信息以便后续联系，并承诺48小时内通过电话告知处理结果。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "\n",
      "视角2 temp=0.50\n",
      "  ```json\n",
      "{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映购买的卡收到后一直没信号，客服让再充值30元，但用户认为买卡的30元应该作为预存话费，但目前只有30元话费，正常应为60元，质疑充值和买卡费用的使用问题。\",\n",
      "  \"user_request\": \"用户希望确认买卡的30元是否会被作为预存话费使用，并希望解决当前话费金额不足的问题，同时希望得到明确的解释和处理结果。\",\n",
      "  \"cons_progress\": \"客服首先询问用户提供的号码和订单编号，确认用户通过小程序购买，随后查询发现通用余额为0，专用余额为30元，解释为买卡费用已充值。用户质疑充值和买卡费用的用途，客服表示买卡费用已激活充值，但系统查询不到，随后转接省内客服核实，并承诺48小时内通过电话联系用户解决。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "```\n",
      "\n",
      "视角3 temp=0.80\n",
      "  ```json\n",
      "{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反馈购买的卡收到后，快递小哥开卡后一直没信号，打电话给客服后被要求再充值30元，但目前只有30元话费，用户认为不应该只有30元，而应该是60元，质疑买卡的30元是否被正确使用。\",\n",
      "  \"user_request\": \"用户希望确认买卡的30元是否被正确作为预存话费使用，以及为何目前只有30元话费，要求客服核实并解决这个问题。\",\n",
      "  \"cons_progress\": \"客服首先询问用户提供了收货号码和身份证号，随后查询发现未找到信息，询问用户购买渠道并确认订单编号。之后查询显示通用余额为0，专用余额为30元，客服解释话费是订单内的30元激活充值，但用户不理解，要求截图充值账单，客服随后转接省内客服核实，并承诺48小时内通过电话联系用户解决。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "```\n",
      "\n",
      "视角4 temp=1.00\n",
      "  ```json\n",
      "{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡到货后没有信号，打电话给客服后被要求再充值30元，但目前只有30元话费，用户认为购买卡时的30元不应作为预存话费，而是应该作为初始话费，但实际只有30元，用户对此表示困惑和不满，并提到可能投诉监管部门。\",\n",
      "  \"user_request\": \"用户希望明确购买卡时的30元是否应作为初始话费，且希望确认为何当前只有30元话费，而非预期的60元，并希望得到合理的解释和解决方案。\",\n",
      "  \"cons_progress\": \"客服首先尝试查询用户提供的号码信息，但未找到相关信息，随后询问用户购买渠道和订单编号。用户确认是通过小程序购买，订单时间为2025-05-08 21:25:59。客服查询发现话费是订单内的30元激活已充值，但用户不理解，要求进一步解释。客服表示买卡的30元即为话费，并要求用户提供能联系到的手机号和姓名，以便通过电话告知处理结果。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "```\n",
      "\n",
      "视角5 temp=1.40\n",
      "  ```json\n",
      "{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"用户\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映购买的号码卡到账后一直没信号，电话客服让其再充值30元，但目前只有30元话费，用户质疑为什么购买卡的30元没有作为预存话费，认为这不符合预期。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的30元是否被正确计为预存话费，且要求解释为何当前话费只有30元，而非预期的60元，并希望得到明确答复和处理。\",\n",
      "  \"cons_progress\": \"客服询问用户通过什么渠道购买，确认订单编号后，查询发现未查询到信息。随后确认用户是通过小程序购买，订单号为2025-05-08 21:25:59。客服告知用户话费是订单内的30元激活已充值，但用户表示听不懂，并质疑购买卡的30元是否被正确处理。客服表示该30元即为买卡费用，但用户表示已充值30元，且对处理方式不满，要求进一步解释。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "```\n",
      "\n",
      "视角6 temp=2.00\n",
      "  {\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购的号码卡到达后一直没有信号，之前联系客服被建议充值30元，但目前话费只显示30元，用户质疑买卡的钱是否应作为预存话费，且对客服解释不清晰表示不满。\",\n",
      "  \"user_request\": \"用户希望确认买卡的30元是否会被作为预存话费使用，并要求解决当前话费不足的问题，同时希望得到明确答复和后续处理进度。\",\n",
      "  \"cons_progress\": \"客服首先询问用户是否通过小程序购买，并确认订单编号；随后查询用户账户余额，发现专用余额为30元，但无法查询到激活充值记录；因信息不明确，客服请求用户提供能联系到的手机号和姓名，并转接省内客服核实问题，承诺48小时内通过电话跟进处理。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "\n",
      "\n",
      "=== 多视角分析最终结果 ===\n",
      "{\n",
      "  \"总视角数\": 6,\n",
      "  \"topk结果\": [\n",
      "    {\n",
      "      \"视角\": \"视角3\",\n",
      "      \"权重\": 0.16714109480381012,\n",
      "      \"复杂度\": 0.9822615777887947,\n",
      "      \"回答\": \"```json\\n{\\n  \\\"order_number\\\": \\\"2025-05-08 21:25:59\\\",\\n  \\\"business_Number\\\": \\\"15767962194\\\",\\n  \\\"name\\\": \\\"\\\",\\n  \\\"contact_Phone\\\": \\\"15767962194\\\",\\n  \\\"user_feedback_issue\\\": \\\"用户反馈购买的卡收到后，快递小哥开卡后一直没信号，打电话给客服后被要求再充值30元，但目前只有30元话费，用户认为不应该只有30元，而应该是60元，质疑买卡的30元是否被正确使用。\\\",\\n  \\\"user_request\\\": \\\"用户希望确认买卡的30元是否被正确作为预存话费使用，以及为何目前只有30元话费，要求客服核实并解决这个问题。\\\",\\n  \\\"cons_progress\\\": \\\"客服首先询问用户提供了收货号码和身份证号，随后查询发现未找到信息，询问用户购买渠道并确认订单编号。之后查询显示通用余额为0，专用余额为30元，客服解释话费是订单内的30元激活充值，但用户不理解，要求截图充值账单，客服随后转接省内客服核实，并承诺48小时内通过电话联系用户解决。\\\",\\n  \\\"cardType\\\": \\\"充值\\\"\\n}\\n```\"\n",
      "    },\n",
      "    {\n",
      "      \"视角\": \"视角5\",\n",
      "      \"权重\": 0.16708935797214508,\n",
      "      \"复杂度\": 0.9830827737173985,\n",
      "      \"回答\": \"```json\\n{\\n  \\\"order_number\\\": \\\"2025-05-08 21:25:59\\\",\\n  \\\"business_Number\\\": \\\"15767962194\\\",\\n  \\\"name\\\": \\\"用户\\\",\\n  \\\"contact_Phone\\\": \\\"15767962194\\\",\\n  \\\"user_feedback_issue\\\": \\\"用户反映购买的号码卡到账后一直没信号，电话客服让其再充值30元，但目前只有30元话费，用户质疑为什么购买卡的30元没有作为预存话费，认为这不符合预期。\\\",\\n  \\\"user_request\\\": \\\"用户希望确认购买卡的30元是否被正确计为预存话费，且要求解释为何当前话费只有30元，而非预期的60元，并希望得到明确答复和处理。\\\",\\n  \\\"cons_progress\\\": \\\"客服询问用户通过什么渠道购买，确认订单编号后，查询发现未查询到信息。随后确认用户是通过小程序购买，订单号为2025-05-08 21:25:59。客服告知用户话费是订单内的30元激活已充值，但用户表示听不懂，并质疑购买卡的30元是否被正确处理。客服表示该30元即为买卡费用，但用户表示已充值30元，且对处理方式不满，要求进一步解释。\\\",\\n  \\\"cardType\\\": \\\"充值\\\"\\n}\\n```\"\n",
      "    }\n",
      "  ],\n",
      "  \"所有视角权重\": [\n",
      "    [\n",
      "      \"视角3\",\n",
      "      0.16714109480381012\n",
      "    ],\n",
      "    [\n",
      "      \"视角5\",\n",
      "      0.16708935797214508\n",
      "    ],\n",
      "    [\n",
      "      \"视角4\",\n",
      "      0.16692586243152618\n",
      "    ],\n",
      "    [\n",
      "      \"视角2\",\n",
      "      0.16677600145339966\n",
      "    ],\n",
      "    [\n",
      "      \"视角6\",\n",
      "      0.16623756289482117\n",
      "    ],\n",
      "    [\n",
      "      \"视角1\",\n",
      "      0.16583016514778137\n",
      "    ]\n",
      "  ],\n",
      "  \"复杂度指标\": [\n",
      "    [\n",
      "      \"视角3\",\n",
      "      0.9822615777887947\n",
      "    ],\n",
      "    [\n",
      "      \"视角5\",\n",
      "      0.9830827737173985\n",
      "    ],\n",
      "    [\n",
      "      \"视角4\",\n",
      "      0.9818254939210428\n",
      "    ],\n",
      "    [\n",
      "      \"视角2\",\n",
      "      0.9806215740498134\n",
      "    ],\n",
      "    [\n",
      "      \"视角6\",\n",
      "      0.9754271670456053\n",
      "    ],\n",
      "    [\n",
      "      \"视角1\",\n",
      "      0.973586918793199\n",
      "    ]\n",
      "  ],\n",
      "  \"参数配置\": {\n",
      "    \"complexity_weight_ratio\": 0.6,\n",
      "    \"length_weight\": 0.4,\n",
      "    \"diversity_weight\": 0.5,\n",
      "    \"variance_weight\": 0.3,\n",
      "    \"temperature_settings\": [\n",
      "      0.2,\n",
      "      0.5,\n",
      "      0.8,\n",
      "      1,\n",
      "      1.4,\n",
      "      2\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "import concurrent.futures\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Any, Optional, Union\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# 下载NLTK所需资源（首次运行时取消注释）\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "class ComplexityWeightedAggregationLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_perspectives=3, complexity_weight_ratio=0.7):\n",
    "        \"\"\"\n",
    "        基于复杂度加权的聚合层：\n",
    "        - 保留全局聚合路径\n",
    "        - 用文本复杂度替代注意力权重\n",
    "        - complexity_weight_ratio控制复杂度权重影响程度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_perspectives = num_perspectives\n",
    "        self.complexity_weight_ratio = complexity_weight_ratio\n",
    "        \n",
    "        # 第一级：两两视角聚合\n",
    "        self.pairwise_aggregators = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_size * 2, hidden_size),\n",
    "                torch.nn.LayerNorm(hidden_size),\n",
    "                torch.nn.GELU()\n",
    "            )\n",
    "            for _ in range(num_perspectives * (num_perspectives - 1) // 2)\n",
    "        ])\n",
    "        \n",
    "        # 第二级：全局聚合\n",
    "        num_pairwise = num_perspectives * (num_perspectives - 1) // 2\n",
    "        self.global_aggregator = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * num_pairwise, hidden_size * 2),\n",
    "            torch.nn.LayerNorm(hidden_size * 2),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.15),\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size)\n",
    "        )\n",
    "        \n",
    "        # 文本复杂度计算模型（外部传入）\n",
    "        self.complexity_model = None\n",
    "        self.complexity_tokenizer = None\n",
    "    \n",
    "    def set_complexity_tools(self, model: AutoModel, tokenizer: AutoTokenizer):\n",
    "        \"\"\"设置复杂度计算所需的模型和分词器\"\"\"\n",
    "        self.complexity_model = model\n",
    "        self.complexity_tokenizer = tokenizer\n",
    "    \n",
    "    def forward(self, encoded_responses: List[torch.Tensor], response_texts: List[str]):\n",
    "        \"\"\"\n",
    "        前向传播过程\n",
    "        \n",
    "        参数：\n",
    "            encoded_responses: 视角特征列表 [num_perspectives, hidden_size]\n",
    "            response_texts: 视角文本列表 [num_perspectives]\n",
    "        \"\"\"\n",
    "        stacked = torch.stack(encoded_responses)  # [num_perspectives, hidden_size]\n",
    "        \n",
    "        # 第一阶段：两两视角聚合\n",
    "        pairwise_outputs = []\n",
    "        idx = 0\n",
    "        for i in range(self.num_perspectives):\n",
    "            for j in range(i + 1, self.num_perspectives):\n",
    "                pair = torch.cat([stacked[i], stacked[j]], dim=-1).unsqueeze(0)\n",
    "                pairwise_outputs.append(self.pairwise_aggregators[idx](pair))\n",
    "                idx += 1\n",
    "        \n",
    "        # 第二阶段：全局聚合\n",
    "        pairwise_concat = torch.cat(pairwise_outputs, dim=-1)  # [1, hidden_size*num_pairs]\n",
    "        global_repr = self.global_aggregator(pairwise_concat)  # [1, hidden_size]\n",
    "        \n",
    "        # 第三阶段：基于复杂度的权重计算\n",
    "        complexities = [\n",
    "            calculate_complexity(text, self.complexity_model, self.complexity_tokenizer)\n",
    "            for text in response_texts\n",
    "        ]\n",
    "        \n",
    "        # 归一化为概率分布\n",
    "        complexities = torch.tensor(complexities, dtype=torch.float32)\n",
    "        weights = torch.softmax(complexities, dim=-1)  # [num_perspectives]\n",
    "        \n",
    "        # 原始视角的加权和\n",
    "        weighted_aggregation = torch.sum(\n",
    "            stacked * weights.t().unsqueeze(-1),\n",
    "            dim=0\n",
    "        )  # [hidden_size]\n",
    "        \n",
    "        # 最终输出融合\n",
    "        final_output = (self.complexity_weight_ratio * weighted_aggregation.unsqueeze(0) + \n",
    "                       (1 - self.complexity_weight_ratio) * global_repr)  # [1, hidden_size]\n",
    "        \n",
    "        return final_output, weights\n",
    "\n",
    "def load_encoder_model() -> Tuple[AutoModel, AutoTokenizer]:\n",
    "    \"\"\"加载预训练的BERT编码器和分词器\"\"\"\n",
    "    model_name = \"/app/sda1/xiangyue/model/bert-base-chinese\"\n",
    "    return AutoModel.from_pretrained(model_name), AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def encode_text(text: str, model: AutoModel, tokenizer: AutoTokenizer) -> torch.Tensor:\n",
    "    \"\"\"将文本编码为BERT的CLS向量\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        return model(**inputs).last_hidden_state[:, 0, :].squeeze(0)  # [hidden_size]\n",
    "\n",
    "def calculate_complexity(text: str, model: AutoModel, tokenizer: AutoTokenizer) -> float:\n",
    "    \"\"\"\n",
    "    计算文本复杂度（多维度指标融合）：\n",
    "    1. 文本长度复杂度\n",
    "    2. 词汇多样性（TF-IDF熵）\n",
    "    3. 语义嵌入方差\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    \n",
    "    # 1. 文本长度复杂度（对数归一化）\n",
    "    word_count = len(word_tokenize(text))\n",
    "    length_score = np.log(word_count + 1) / np.log(100 + 1)  # 归一化到[0,1]\n",
    "    \n",
    "    # 2. 词汇多样性（TF-IDF熵）\n",
    "    words = [word for word in word_tokenize(text) if word.isalpha() and len(word) > 1]\n",
    "    if len(words) < 2:\n",
    "        diversity_score = 0.0\n",
    "    else:\n",
    "        word_freq = Counter(words)\n",
    "        probs = np.array(list(word_freq.values()), dtype=float) / len(words)\n",
    "        diversity_score = -np.sum(probs * np.log(probs + 1e-10)) / np.log(len(word_freq))\n",
    "        diversity_score = max(0.0, min(1.0, diversity_score))  # 裁剪到[0,1]\n",
    "    \n",
    "    # 3. 语义嵌入方差（BERT各token向量的方差）\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.squeeze(0)\n",
    "        valid_mask = inputs.input_ids.squeeze(0) != 0  # 忽略padding\n",
    "        valid_embeddings = embeddings[valid_mask]\n",
    "        if len(valid_embeddings) < 2:\n",
    "            semantic_variance = 0.0\n",
    "        else:\n",
    "            variance = torch.var(valid_embeddings, dim=0).mean().item()\n",
    "            # 动态范围归一化（假设方差通常在0.01-1.0之间）\n",
    "            semantic_variance = (variance - 0.01) / (1.0 - 0.01) if variance > 0.01 else 0.0\n",
    "            semantic_variance = max(0.0, min(1.0, semantic_variance))  # 裁剪到[0,1]\n",
    "    \n",
    "    # 综合复杂度分数（各指标加权求和）\n",
    "    complexity_score = 0.3 * length_score + 0.3 * diversity_score + 0.4 * semantic_variance\n",
    "    return max(complexity_score, 1e-6)  # 防止全零\n",
    "\n",
    "def process_perspective(\n",
    "    index: int, \n",
    "    question: str, \n",
    "    encoder_model: AutoModel, \n",
    "    tokenizer: AutoTokenizer, \n",
    "    llm: callable, \n",
    "    temperature: float\n",
    ") -> Tuple[int, str, torch.Tensor]:\n",
    "    \"\"\"处理单个视角：生成回答 -> 编码向量\"\"\"\n",
    "    response = llm(f\"{question}\", temperature=temperature)\n",
    "    encoded = encode_text(response, encoder_model, tokenizer)\n",
    "    return index, response, encoded\n",
    "\n",
    "def multi_perspective_analysis(\n",
    "    metaprompt: str, \n",
    "    p: int = 3, \n",
    "    topk: int = 1, \n",
    "    llm: callable = None, \n",
    "    temperature_settings: List[float] = None,\n",
    "    complexity_weight_ratio: float = 0.4,\n",
    "    hidden_size: int = 768,\n",
    "    length_weight: float = 0.3,\n",
    "    diversity_weight: float = 0.3,\n",
    "    variance_weight: float = 0.4,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    多视角分析主函数：\n",
    "    1. 并行生成p个视角回答\n",
    "    2. 计算各视角复杂度权重\n",
    "    3. 聚合特征并返回topk视角\n",
    "    \n",
    "    参数:\n",
    "        metaprompt: 元提示文本\n",
    "        p: 视角数量\n",
    "        topk: 返回的顶部视角数量\n",
    "        llm: 大语言模型调用函数\n",
    "        temperature_settings: 各视角的温度设置\n",
    "        complexity_weight_ratio: 复杂度权重占比\n",
    "        hidden_size: 隐藏层大小\n",
    "        length_weight: 文本长度复杂度权重\n",
    "        diversity_weight: 词汇多样性权重\n",
    "        variance_weight: 语义嵌入方差权重\n",
    "    \"\"\"\n",
    "    global calculate_complexity\n",
    "    \n",
    "    if llm is None:\n",
    "        llm = llm_qwen  # 默认使用模拟LLM\n",
    "    \n",
    "    # 处理temperature设置\n",
    "    if temperature_settings is None:\n",
    "        temperatures = [0.1] * p\n",
    "    elif isinstance(temperature_settings, (int, float)):\n",
    "        temperatures = [temperature_settings] * p\n",
    "    elif len(temperature_settings) == p:\n",
    "        temperatures = temperature_settings\n",
    "    else:\n",
    "        raise ValueError(\"temperature_settings需为单个值或长度为p的列表\")\n",
    "    \n",
    "    # 初始化模型\n",
    "    encoder_model, tokenizer = load_encoder_model()\n",
    "    \n",
    "    # 创建闭包以修改复杂度计算的权重\n",
    "    original_calculate_complexity = calculate_complexity\n",
    "    def calculate_complexity_with_weights(text: str, model: AutoModel, tokenizer: AutoTokenizer) -> float:\n",
    "        \"\"\"使用自定义权重的文本复杂度计算函数\"\"\"\n",
    "        if not text:\n",
    "            return 0.0\n",
    "        \n",
    "        # 1. 文本长度复杂度\n",
    "        word_count = len(word_tokenize(text))\n",
    "        length_score = np.log(word_count + 1) / np.log(100 + 1)\n",
    "        \n",
    "        # 2. 词汇多样性\n",
    "        words = [word for word in word_tokenize(text) if word.isalpha() and len(word) > 1]\n",
    "        if len(words) < 2:\n",
    "            diversity_score = 0.0\n",
    "        else:\n",
    "            word_freq = Counter(words)\n",
    "            probs = np.array(list(word_freq.values()), dtype=float) / len(words)\n",
    "            diversity_score = -np.sum(probs * np.log(probs + 1e-10)) / np.log(len(word_freq))\n",
    "            diversity_score = max(0.0, min(1.0, diversity_score))\n",
    "        \n",
    "        # 3. 语义嵌入方差\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(**inputs).last_hidden_state.squeeze(0)\n",
    "            valid_mask = inputs.input_ids.squeeze(0) != 0\n",
    "            valid_embeddings = embeddings[valid_mask]\n",
    "            if len(valid_embeddings) < 2:\n",
    "                semantic_variance = 0.0\n",
    "            else:\n",
    "                variance = torch.var(valid_embeddings, dim=0).mean().item()\n",
    "                semantic_variance = (variance - 0.01) / (1.0 - 0.01) if variance > 0.01 else 0.0\n",
    "                semantic_variance = max(0.0, min(1.0, semantic_variance))\n",
    "        \n",
    "        # 使用传入的权重\n",
    "        complexity_score = (length_weight * length_score + \n",
    "                           diversity_weight * diversity_score + \n",
    "                           variance_weight * semantic_variance)\n",
    "        return max(complexity_score, 1e-6)\n",
    "    \n",
    "    # 临时替换复杂度计算函数\n",
    "    calculate_complexity = calculate_complexity_with_weights\n",
    "    \n",
    "    aggregation_model = ComplexityWeightedAggregationLayer(\n",
    "        num_perspectives=p, \n",
    "        complexity_weight_ratio=complexity_weight_ratio,\n",
    "        hidden_size=hidden_size\n",
    "    )\n",
    "    aggregation_model.set_complexity_tools(encoder_model, tokenizer)\n",
    "    aggregation_model.eval()  # 设置为评估模式\n",
    "    \n",
    "    # 并行处理多视角\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=p) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_perspective, \n",
    "                i, \n",
    "                metaprompt, \n",
    "                encoder_model, \n",
    "                tokenizer, \n",
    "                llm, \n",
    "                temperatures[i]\n",
    "            ) for i in range(p)\n",
    "        ]\n",
    "        results = [future.result() for future in futures]\n",
    "    \n",
    "    # 恢复原始的复杂度计算函数\n",
    "    calculate_complexity = original_calculate_complexity\n",
    "    \n",
    "    # 整理结果\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    encoded_responses = [enc for _, _, enc in results]\n",
    "    response_texts = [resp for _, resp, _ in results]\n",
    "    \n",
    "    # 打印各视角信息（含复杂度）\n",
    "    print(\"\\n=== 各视角分析结果 ===\")\n",
    "    complexities = [\n",
    "        calculate_complexity_with_weights(text, encoder_model, tokenizer)\n",
    "        for text in response_texts\n",
    "    ]\n",
    "    for idx, (text, temp, comp) in enumerate(zip(response_texts, temperatures, complexities), start=1):\n",
    "        # print(f\"视角{idx} (temp={temp:.2f}, 复杂度={comp:.4f}):\")\n",
    "        print(f\"视角{idx} temp={temp:.2f}\")\n",
    "        print(f\"  {text}\\n\")\n",
    "    \n",
    "    if not encoded_responses:\n",
    "        return {\"error\": \"未获取到有效视角\"}\n",
    "    \n",
    "    # 执行复杂度加权聚合\n",
    "    with torch.no_grad():\n",
    "        aggregated_output, weights = aggregation_model(encoded_responses, response_texts)\n",
    "    \n",
    "    # 整理topk结果\n",
    "    sorted_items = sorted(\n",
    "        [(i, f\"视角{i+1}\", weights[i].item(), complexities[i]) for i in range(p)],\n",
    "        key=lambda x: x[2], reverse=True\n",
    "    )\n",
    "    top_indices = [item[0] for item in sorted_items[:topk]]\n",
    "    top_perspectives = [\n",
    "        {\n",
    "            \"视角\": f\"视角{idx+1}\",\n",
    "            \"权重\": weights[idx].item(),\n",
    "            \"复杂度\": complexities[idx],\n",
    "            \"回答\": response_texts[idx]\n",
    "        }\n",
    "        for idx in top_indices\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"总视角数\": p,\n",
    "        \"topk结果\": top_perspectives,\n",
    "        \"所有视角权重\": [(item[1], item[2]) for item in sorted_items],\n",
    "        \"复杂度指标\": [(item[1], item[3]) for item in sorted_items],\n",
    "        \"参数配置\": {\n",
    "            \"complexity_weight_ratio\": complexity_weight_ratio,\n",
    "            \"length_weight\": length_weight,\n",
    "            \"diversity_weight\": diversity_weight,\n",
    "            \"variance_weight\": variance_weight,\n",
    "            \"temperature_settings\": temperatures\n",
    "        }\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    metaprompt = \"\"\"\n",
    "任务： 从给定的客服对话记录中提取关键信息，并生成一个结构化的 JSON 格式输出。\n",
    "\n",
    "要求：\n",
    "1. 提取以下字段：\n",
    "  order_number（从系统消息或用户反馈中查找办理业务订单号）\n",
    "  business_Number（用户要办理的手机号）\n",
    "  name（用户提供的姓名，区分客服的姓名，和用户的姓名）\n",
    "  contact_Phone（用户提供的手机号）\n",
    "  user_feedback_issue（用户的主要投诉或咨询内容，尽量详细，且要以客服的视角描述）\n",
    "  user_request（用户希望解决的问题或需求，尽量详细，且要以客服的视角描述）\n",
    "  cons_progress（工号xx开头的客服为用户查询了什么，和用户确认了什么，尽量详细）\n",
    "  cardType（判断用户咨询的业务类型号的卡，必须是这些门类：充值 权益包 流量包 业务办理 不确定）\n",
    "2. 确保 JSON 格式正确，字段值尽量从对话原文中提取\n",
    "3. 如果没有输出为空值！！！\n",
    "最终输出格式：\n",
    "{\n",
    "  \"order_number\": \"\",\n",
    "  \"business_Number\": \"\",\n",
    "  \"name\": \"\",\n",
    "  \"contact_Phone\": \"\",\n",
    "  \"user_feedback_issue\": \"\",\n",
    "  \"user_request\": \"\",\n",
    "  \"cons_progress\": \"\",\n",
    "  \"cardType\": \"\"\n",
    "}\n",
    "下面是要处理的客服对话片段：\n",
    "\n",
    "(系统消息)      2025-05-11 14:13:04\n",
    "正在为您接入人工服务，请稍等；您也可以发送【00】退出服务\n",
    "(系统消息)      2025-05-11 14:13:04\n",
    "客户IM号码（TYMY_H5dq250511024844208）已关联号码（TYMY_H515767962194）\n",
    "梁鑫一(95047)      2025-05-11 14:13:05\n",
    "您好，感谢您的耐心等待，系统已为您接入人工服务。中国电信95047号客服为您服务。\n",
    "(0)      2025-05-11 14:13:05\n",
    "【系统消息】15767962194,null,null ; 不可办理5G升级包\n",
    "(0)      2025-05-11 14:13:05\n",
    "人工[文本]\n",
    "(0)      2025-05-11 14:13:05\n",
    "【系统消息】亲，您可以#LinkIDSwitchToCSR马上召唤人工客服为您服务。<br/>以下是小知经常回答的问题哦：<br/>[1]购买号卡后找不到订单<br/>[2]我的卡有余额但无法使用<br/>[3]我想换个套餐有什么推荐吗<br/>[4]携号转网问题<br/>[5]我的卡提示被保护，停机了[文本]\n",
    "(0)      2025-05-11 14:13:05\n",
    "【客服请回复】请及时答复用户问题\n",
    "(0)      2025-05-11 14:13:27\n",
    "这个卡购买卡的30块不会作为预存话费的吗[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:13:49\n",
    "尊敬的用户您好！这里是中国电信网上营业厅人工客服，工号95047，请问您有什么问题需要帮助吗？我将尽力为您提供最优质的服务！\n",
    "梁鑫一(95047)      2025-05-11 14:13:53\n",
    "辛苦您方便提供一下收货号码或身份证号吗？\n",
    "(0)      2025-05-11 14:14:04\n",
    "15767962194[文本]\n",
    "(0)      2025-05-11 14:15:18\n",
    "我昨天号码卡到了，快递小哥开卡后一直没信号，我打电话你们客服，客服让我再充值30元，但是现在只有30块话费，正常来说不应该是60块话费吗？[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:15:30\n",
    "亲，正在为您积极查询中，预计需要1到3分钟，请您稍等。 （正在为您查询~!这句无需回复喔~）\n",
    "梁鑫一(95047)      2025-05-11 14:17:02\n",
    "15767962194未查询到信息，您是通过什么渠道购买的呢？方便提供订单编号吗？\n",
    "梁鑫一(95047)      2025-05-11 14:17:16\n",
    "抱歉亲亲查询错误\n",
    "(0)      2025-05-11 14:17:17\n",
    "你们这个小程序啊[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:17:19\n",
    "2025-05-08 21:25:59下单的这个吗？\n",
    "(0)      2025-05-11 14:17:23\n",
    "对啊[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:17:47\n",
    "亲，请您稍等不要离开呦~我现在为您查询，谢谢亲的配合与理解。\n",
    "梁鑫一(95047)      2025-05-11 14:18:01\n",
    "通用可用余额: 0专用余额: 30\n",
    "梁鑫一(95047)      2025-05-11 14:18:02\n",
    "您好，为了您能得到更专业的服务，您所咨询的问题需要转到号码归属（省）专席为您跟进（以上对话记录也会一同转接），转接期间请勿退出，如线路繁忙，可以联系号码归属省10000万号，同意转接回复1\n",
    "(0)      2025-05-11 14:18:38\n",
    "怎么回事？[文本]\n",
    "(0)      2025-05-11 14:18:48\n",
    "我就是问你怎么话费只有30块啊[文本]\n",
    "(0)      2025-05-11 14:19:05\n",
    "这个卡是买卡的30块不是作为预存话费的吗？[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:19:10\n",
    "话费是您订单内的30激活已充值\n",
    "(0)      2025-05-11 14:19:13\n",
    "听不懂话吗？[文本]\n",
    "(0)      2025-05-11 14:19:22\n",
    "那我买卡的30块呢[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:19:33\n",
    "这个就是买卡的亲亲\n",
    "梁鑫一(95047)      2025-05-11 14:19:40\n",
    "激活中要求您充值的这边查询不到\n",
    "梁鑫一(95047)      2025-05-11 14:19:41\n",
    "为您转接省内客服为您核实看看好吗？\n",
    "(0)      2025-05-11 14:19:57\n",
    "买卡的钱不会变成话费的意思是吗？[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:20:52\n",
    "会\n",
    "梁鑫一(95047)      2025-05-11 14:20:55\n",
    "已经到了亲亲\n",
    "(0)      2025-05-11 14:21:02\n",
    "并没有啊[文本]\n",
    "(0)      2025-05-11 14:21:15\n",
    "我现在的30块是后面充值的啊[文本]\n",
    "(0)      2025-05-11 14:21:24\n",
    "现在你们两边踢皮球还是怎么样[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:21:36\n",
    "亲，您说的问题这边为您记录反馈，请您提供一下能联系到您的手机号和您的姓名，给您带来不便请您谅解，我们会通过电话的方式告知您处理结果，请您保持电话畅通\n",
    "梁鑫一(95047)      2025-05-11 14:21:54\n",
    "您激活充值的30 账单麻烦截图\n",
    "(0)      2025-05-11 14:22:22\n",
    "SVU2OE1NIXhqeFMhUyFPTyFYO05IT1lqak5jeFlPbUNR1007-100-100-11-lnsy.png\n",
    "梁鑫一(95047)      2025-05-11 14:22:47\n",
    "亲亲稍等加载图片看下\n",
    "(0)      2025-05-11 14:22:55\n",
    "昨天充值的，赶紧看怎么回事啊，不然我就工信局投诉你们欺骗消费者了[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:24:45\n",
    "15767962194这个号码能联系到您吗？\n",
    "(0)      2025-05-11 14:25:29\n",
    "可以[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:25:51\n",
    "您好，您反馈的问题，客服已反馈到相关部门，预计48小时内，我们的工作人员会使用4008开头的电话跟您15767962194的号码联系，请您保持电话畅通，感谢您的理解！\n",
    "梁鑫一(95047)      2025-05-11 14:27:44\n",
    "亲亲您还有其他需要帮助的吗？\n",
    "(系统消息)      2025-05-11 14:29:45\n",
    "请问您还在线吗？ 如随后2分钟仍未收到您的消息，本次会话将暂时结束；如您的问题已解决，可发送【00】结束本次会话。\n",
    "(系统消息)      2025-05-11 14:29:45\n",
    "用户2分钟未发言或回复消息，系统已向用户发送提示消息\n",
    "(系统消息)      2025-05-11 14:30:05\n",
    "【系统消息】用户主动结束了该会话\n",
    "\"\"\"\n",
    "\n",
    "    # 手动设置每次并发的温度值\n",
    "    # manual_temperatures = [0.2, 0.4, 0.6, 0.8, 1, 1.4,1.8,2]\n",
    "    # manual_temperatures = [0.2, 0.4, 0.6, 0.8, 1, 1.4, 2]\n",
    "    manual_temperatures = [0.2, 0.5, 0.8, 1, 1.4, 2]\n",
    "    # manual_temperatures = [0.2, 0.6, 0.8, 1.4, 2]\n",
    "    # manual_temperatures = [0.2, 0.6, 1, 2]\n",
    "    # manual_temperatures = [0.2, 0.8, 2] # 客服总结\n",
    "    # manual_temperatures = [0.2, 2] # topk = 1\n",
    "\n",
    "    \n",
    "    # 执行多视角分析，将所有参数都放在函数调用中\n",
    "    result = multi_perspective_analysis(\n",
    "        metaprompt=metaprompt,\n",
    "        p=len(manual_temperatures),  # 视角数量\n",
    "        topk=2,  # 返回前2个视角\n",
    "        temperature_settings=manual_temperatures,\n",
    "        complexity_weight_ratio=0.6,  # 复杂度权重占比\n",
    "        hidden_size=768,  # 隐藏层大小\n",
    "        length_weight=0.4,  # 文本长度复杂度权重\n",
    "        diversity_weight=0.5,  # 词汇多样性权重\n",
    "        variance_weight=0.3  # 语义嵌入方差权重\n",
    "    )\n",
    "\n",
    "    # 输出结果（格式化JSON）\n",
    "    print(\"\\n=== 多视角分析最终结果 ===\")\n",
    "    print(json.dumps(result, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c0d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个(temperature=0.20)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡在激活后没有收到预存的30元话费，只收到30元充值的话费，认为购买卡的30元不应作为充值使用，而是应该作为预存话费，否则可能构成欺骗消费者行为。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的30元是否会被系统自动充值为话费，如果不会，希望得到明确解释，并希望尽快解决当前话费不足的问题，避免投诉。\",\n",
      "  \"cons_progress\": \"客服首先尝试查询用户号码信息，但未找到相关记录，随后询问用户购买渠道和订单编号。用户提供了订单编号为2025-05-08 21:25:59，并说明是通过小程序购买。客服进一步确认用户号码的余额情况，发现通用余额为0，专用余额为30元，解释该30元是订单内的激活充值。用户表示不理解，要求截图充值记录，客服随后要求用户提供能联系到的手机号和姓名，并承诺48小时内通过电话联系用户解决。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第2个(temperature=0.40)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡在激活后没有收到预存的30元话费，只收到了后续充值的30元，且对客服的解释表示不满，认为存在误导。\",\n",
      "  \"user_request\": \"用户希望确认购买卡时的30元是否被正确预存为话费，并要求客服核实问题，避免因误解而引发投诉。\",\n",
      "  \"cons_progress\": \"客服首先尝试查询用户号码信息，但未找到相关记录，随后询问用户购买渠道和订单编号。用户提供了订单时间，客服确认了订单信息，但系统显示通用余额为0，专用余额为30。客服解释该30元是激活充值的，但用户表示不理解，要求进一步核实。客服请求用户提供充值账单截图，并转接省内客服处理。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第3个(temperature=0.60)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡在激活后没有收到预存的30元话费，只充值了30元，但用户认为买卡的钱应该作为预存话费，现在只有30元，而用户认为应该是60元。\",\n",
      "  \"user_request\": \"用户希望确认买卡的30元是否会被作为预存话费使用，并希望解决当前话费余额不足的问题，同时表示如果不解决可能会向工信局投诉。\",\n",
      "  \"cons_progress\": \"客服首先询问用户提供了订单编号和手机号，随后查询发现该号码未查询到信息，用户说明是通过小程序购买的，并提供了订单编号。客服进一步确认用户充值情况，发现用户激活充值的30元账单，但系统显示专用余额为30元，用户表示不理解，客服要求用户提供能联系到的手机号和姓名，并告知将反馈问题，预计48小时内通过电话联系用户。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第4个(temperature=0.80)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映购买的号码卡到货后一直没信号，客服建议充值30元，但用户认为购买卡的30元不应作为预存话费，目前只有30元话费，而正常应为60元，用户质疑是否存在问题。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的30元是否被正确作为预存话费，并要求解决当前话费不足的问题，同时表示如果问题未解决可能进行投诉。\",\n",
      "  \"cons_progress\": \"客服首先询问用户提供的号码和身份证号，随后查询发现无法获取相关信息，用户说明是通过小程序购买，客服确认订单号为2025-05-08 21:25:59。客服查询发现话费是订单内的30元激活充值，但系统查询不到该充值记录。客服告知用户需要提供能联系到的手机号和姓名，并要求用户截图充值账单以进一步核实问题，同时承诺48小时内通过电话联系用户处理。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第5个(temperature=1.00)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购的号码卡到货后一直没信号，之前联系客服被要求再充值30元，但目前只有30元话费，用户认为买卡的30元应该作为预存话费，但实际并未到账，怀疑存在消费欺诈。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的30元是否被正确计入预存话费，并要求核实充值情况，同时希望得到明确的解释和解决方案，避免进一步投诉。\",\n",
      "  \"cons_progress\": \"客服首先询问用户提供的号码和身份信息，确认用户通过小程序购买卡，并查询订单信息。随后发现用户激活充值的30元账单无法查询到，因此转接省内客服进一步核实。客服表示已将问题反馈至相关部门，并承诺48小时内通过电话联系用户解决。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第6个(temperature=1.40)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡到货后没有信号，之前客服建议充值30元，但用户认为充值的30元不应仅作为预存话费，而应该包含在卡内话费中，现在卡内只有30元话费，用户质疑是否存在操作失误或欺骗行为。\",\n",
      "  \"user_request\": \"用户希望明确充值的30元是否已正确作为预存话费，且要求核实卡内话费的来源及是否存在问题，避免因误解或操作失误导致不满。\",\n",
      "  \"cons_progress\": \"客服在对话中首先确认了用户提供的号码，随后询问用户通过什么渠道购买及订单编号。在查询过程中发现卡内话费为30元，用户表示不满。客服解释说充值的30元是激活时充值的，并建议用户提供能联系到他的手机号和姓名，以便后续通过电话跟进问题。同时，客服将问题反馈至相关部门，并承诺48小时内通过4008开头的电话联系用户。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第7个(temperature=1.80)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反映新购买的号码卡在激活后只有30元话费，而原本以为购买卡的钱（30元）应作为预存话费，但实际没有到账，怀疑存在客服误导或操作错误。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的钱是否会被算作预存话费，且希望核实为何激活后只有30元话费，而不是预期的60元，并要求客服进一步调查并给出明确解释。\",\n",
      "  \"cons_progress\": \"客服先确认了用户提供的号码，查询了订单信息，发现用户通过小程序购买，订单编号为2025-05-08 21:25:59。接着客服查询了余额，显示专用余额为30元。随后客服表示激活充值的30元已到账，但系统无法查询到充值记录，因此建议用户提供能联系到自己的手机号和姓名，并要求用户截图激活充值的账单进行核查。客服同时表示问题已反馈到相关部门，并承诺48小时内通过电话联系用户解决。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "第8个(temperature=2.00)：{\n",
      "  \"order_number\": \"2025-05-08 21:25:59\",\n",
      "  \"business_Number\": \"15767962194\",\n",
      "  \"name\": \"梁鑫一\",\n",
      "  \"contact_Phone\": \"15767962194\",\n",
      "  \"user_feedback_issue\": \"用户反馈购买的号码卡30元未作为预存话费，而是需要额外充值30元，导致用户感到困惑和不满，并提到已联系客服但未得到明确答复，怀疑存在欺骗行为。\",\n",
      "  \"user_request\": \"用户希望确认购买卡的30元是否会被作为预存话费使用，若未被使用，则希望了解原因，并要求客服核实处理，必要时进行投诉。\",\n",
      "  \"cons_progress\": \"客服首先查询了用户提供的号码15767962194，发现未查询到相关信息，随后询问用户购买渠道和订单编号。客服确认用户是通过小程序购买，订单编号为2025-05-08 21:25:59。客服进一步解释话费是订单内的30元激活充值，并提示用户需要提供能联系到的手机号和姓名，以便通过电话告知处理结果。此外，客服请求用户截图激活充值的30元账单以进一步核查。\",\n",
      "  \"cardType\": \"充值\"\n",
      "}\n",
      "{\n",
      "  \"top_perspectives\": [\n",
      "    [\n",
      "      \"response_8\",\n",
      "      0.18898078799247742,\n",
      "      \"{\\n  \\\"order_number\\\": \\\"2025-05-08 21:25:59\\\",\\n  \\\"business_Number\\\": \\\"15767962194\\\",\\n  \\\"name\\\": \\\"梁鑫一\\\",\\n  \\\"contact_Phone\\\": \\\"15767962194\\\",\\n  \\\"user_feedback_issue\\\": \\\"用户反馈购买的号码卡30元未作为预存话费，而是需要额外充值30元，导致用户感到困惑和不满，并提到已联系客服但未得到明确答复，怀疑存在欺骗行为。\\\",\\n  \\\"user_request\\\": \\\"用户希望确认购买卡的30元是否会被作为预存话费使用，若未被使用，则希望了解原因，并要求客服核实处理，必要时进行投诉。\\\",\\n  \\\"cons_progress\\\": \\\"客服首先查询了用户提供的号码15767962194，发现未查询到相关信息，随后询问用户购买渠道和订单编号。客服确认用户是通过小程序购买，订单编号为2025-05-08 21:25:59。客服进一步解释话费是订单内的30元激活充值，并提示用户需要提供能联系到的手机号和姓名，以便通过电话告知处理结果。此外，客服请求用户截图激活充值的30元账单以进一步核查。\\\",\\n  \\\"cardType\\\": \\\"充值\\\"\\n}\"\n",
      "    ],\n",
      "    [\n",
      "      \"response_5\",\n",
      "      0.16944341361522675,\n",
      "      \"{\\n  \\\"order_number\\\": \\\"2025-05-08 21:25:59\\\",\\n  \\\"business_Number\\\": \\\"15767962194\\\",\\n  \\\"name\\\": \\\"梁鑫一\\\",\\n  \\\"contact_Phone\\\": \\\"15767962194\\\",\\n  \\\"user_feedback_issue\\\": \\\"用户反映新购的号码卡到货后一直没信号，之前联系客服被要求再充值30元，但目前只有30元话费，用户认为买卡的30元应该作为预存话费，但实际并未到账，怀疑存在消费欺诈。\\\",\\n  \\\"user_request\\\": \\\"用户希望确认购买卡的30元是否被正确计入预存话费，并要求核实充值情况，同时希望得到明确的解释和解决方案，避免进一步投诉。\\\",\\n  \\\"cons_progress\\\": \\\"客服首先询问用户提供的号码和身份信息，确认用户通过小程序购买卡，并查询订单信息。随后发现用户激活充值的30元账单无法查询到，因此转接省内客服进一步核实。客服表示已将问题反馈至相关部门，并承诺48小时内通过电话联系用户解决。\\\",\\n  \\\"cardType\\\": \\\"充值\\\"\\n}\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import KafkaDsn\n",
    "import torch\n",
    "import concurrent.futures\n",
    "import re\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class HierarchicalAggregationLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_perspectives=3, attn_smoothing=0.1):\n",
    "        \"\"\"\n",
    "        分层聚合层：通过三级处理融合多视角特征\n",
    "        1) 两两视角组合的初级聚合\n",
    "        2) 所有组合结果的全局聚合 \n",
    "        3) 原始视角的注意力加权聚合\n",
    "        \n",
    "        参数：\n",
    "            hidden_size (int): 特征向量的维度（默认768）\n",
    "            num_perspectives (int): 需要聚合的视角数量（默认3）\n",
    "            attn_smoothing (float): 注意力权重的标签平滑系数（默认0.1）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_perspectives = num_perspectives\n",
    "        self.attn_smoothing = attn_smoothing\n",
    "        \n",
    "        # 第一级聚合器：处理所有视角的两两组合\n",
    "        # 共需要n*(n-1)/2个聚合器（n=视角数量）\n",
    "        self.pairwise_aggregators = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_size * 2, hidden_size),  # 将两个视角拼接后线性变换\n",
    "                torch.nn.LayerNorm(hidden_size),               # 层归一化稳定训练\n",
    "                torch.nn.GELU()                                # 高斯误差线性单元激活\n",
    "            )\n",
    "            for _ in range(num_perspectives * (num_perspectives - 1) // 2)\n",
    "        ])\n",
    "        \n",
    "        # 第二级聚合器：整合所有两两组合的结果\n",
    "        num_pairwise = num_perspectives * (num_perspectives - 1) // 2\n",
    "        self.global_aggregator = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * num_pairwise, hidden_size * 2),  # 扩大维度增强表达能力\n",
    "            torch.nn.LayerNorm(hidden_size * 2),                           # 归一化\n",
    "            torch.nn.GELU(),                                               # 非线性激活\n",
    "            torch.nn.Dropout(0.15),                                        # 随机失活防止过拟合\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size)                  # 降维到原始维度\n",
    "        )\n",
    "        \n",
    "        # 注意力机制：计算各原始视角的重要性权重\n",
    "        self.attention = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * num_perspectives, hidden_size),  # 压缩视角拼接信息\n",
    "            torch.nn.LayerNorm(hidden_size),                               # 归一化\n",
    "            torch.nn.GELU(),                                              # 激活函数\n",
    "            torch.nn.Linear(hidden_size, num_perspectives)                 # 输出各视角权重\n",
    "        )\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim=-1)  # 将权重归一化为概率分布\n",
    "        \n",
    "    def forward(self, encoded_responses):\n",
    "        \"\"\"\n",
    "        前向传播过程\n",
    "        \n",
    "        参数：\n",
    "            encoded_responses: 多个视角的特征列表，每个元素形状为[hidden_size]\n",
    "        \n",
    "        返回：\n",
    "            final_output: 聚合后的最终特征 [1, hidden_size]\n",
    "            weights: 各视角的注意力权重 [1, num_perspectives] \n",
    "        \"\"\"\n",
    "        # 将多个视角特征堆叠为张量 [num_perspectives, hidden_size]\n",
    "        stacked = torch.stack(encoded_responses)  \n",
    "        \n",
    "        # 第一阶段：两两视角聚合\n",
    "        pairwise_outputs = []\n",
    "        idx = 0  # 用于选择对应的聚合器\n",
    "        \n",
    "        # 遍历所有独特的视角组合对\n",
    "        for i in range(self.num_perspectives):\n",
    "            for j in range(i + 1, self.num_perspectives):\n",
    "                # 拼接两个视角特征 [1, hidden_size*2]\n",
    "                pair = torch.cat([stacked[i], stacked[j]], dim=-1).unsqueeze(0)\n",
    "                \n",
    "                # 通过对应的聚合器处理\n",
    "                pairwise_outputs.append(self.pairwise_aggregators[idx](pair))\n",
    "                idx += 1\n",
    "        \n",
    "        # 第二阶段：全局聚合\n",
    "        # 拼接所有两两聚合结果 [1, hidden_size*num_pairs]\n",
    "        pairwise_concat = torch.cat(pairwise_outputs, dim=-1)\n",
    "        \n",
    "        # 生成全局聚合特征 [1, hidden_size]\n",
    "        global_repr = self.global_aggregator(pairwise_concat)\n",
    "        \n",
    "        # 第三阶段：注意力权重计算\n",
    "        # 展平所有原始视角特征 [1, num_perspectives*hidden_size]\n",
    "        concat = stacked.view(1, -1)\n",
    "        \n",
    "        # 计算归一化注意力权重 [1, num_perspectives]\n",
    "        weights = self.softmax(self.attention(concat))\n",
    "        \n",
    "        # 应用标签平滑（正则化技术）\n",
    "        if self.attn_smoothing > 0:\n",
    "            uniform_dist = 1 / self.num_perspectives  # 均匀分布\n",
    "            weights = weights * (1 - self.attn_smoothing) + self.attn_smoothing * uniform_dist\n",
    "        \n",
    "        # 计算原始视角的加权和 [hidden_size]\n",
    "        weighted_aggregation = torch.sum(\n",
    "            stacked * weights.t().unsqueeze(-1),  # 加权\n",
    "            dim=0\n",
    "        )\n",
    "        \n",
    "        # 最终输出：全局特征 + 加权原始特征 [1, hidden_size]\n",
    "        final_output = global_repr + weighted_aggregation.unsqueeze(0)\n",
    "        \n",
    "        return final_output, weights\n",
    "\n",
    "def load_encoder_model():\n",
    "    \"\"\"加载预训练的BERT编码器和分词器\"\"\"\n",
    "    model_name = \"D:\\\\xiangyue\\\\model\\\\bert-base-chinese\"\n",
    "    return AutoModel.from_pretrained(model_name), AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def encode_text(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    将文本编码为向量表示\n",
    "    使用BERT模型提取[CLS]标记作为文本的整体表示\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():  # 不计算梯度以提高推理效率\n",
    "        # 提取[CLS]标记的嵌入作为文本表示\n",
    "        return model(**inputs).last_hidden_state[:, 0, :].squeeze(0)\n",
    "\n",
    "def process_perspective(index, question, encoder_model, tokenizer, llm, temperature=0.1):\n",
    "    \"\"\"\n",
    "    处理单个视角：\n",
    "    1. 调用大语言模型生成特定视角的回答\n",
    "    2. 将回答编码为向量表示\n",
    "    返回包含索引、回答文本和编码向量的元组\n",
    "    \n",
    "    参数:\n",
    "        index: 视角索引\n",
    "        question: 问题文本\n",
    "        encoder_model: 编码器模型\n",
    "        tokenizer: 分词器\n",
    "        llm: 大语言模型调用函数\n",
    "        temperature: 控制生成随机性的温度值\n",
    "    \"\"\"\n",
    "    # 使用特定视角前缀提示大语言模型，并传入temperature参数\n",
    "    response = llm(f\"【换一种视角思考{index+1}】{question}\", temperature=temperature)\n",
    "    return index, response, encode_text(response, encoder_model, tokenizer)\n",
    "\n",
    "def multi_perspective_analysis(metaprompt, p=3, topk=1, llm=None, temperature_settings=None):\n",
    "    \"\"\"\n",
    "    多视角分析主函数：\n",
    "    1. 并行生成多个视角的回答\n",
    "    2. 对回答进行编码\n",
    "    3. 使用增强聚合层计算各视角权重\n",
    "    4. 选择权重最高的视角作为最终结果\n",
    "    \n",
    "    参数:\n",
    "        metaprompt: 输入的问题/提示\n",
    "        p: 视角数量\n",
    "        topk: 返回topk个最佳视角\n",
    "        llm: 大语言模型调用函数\n",
    "        temperature_settings: 温度值设置，可以是单个值或长度为p的列表\n",
    "    \"\"\"\n",
    "    # 如果未提供llm，则使用全局导入的llm_qwen\n",
    "    if llm is None:\n",
    "        llm = llm_qwen\n",
    "    \n",
    "    # 处理temperature设置\n",
    "    if temperature_settings is None:\n",
    "        temperatures = [0.1] * p  # 默认所有请求使用0.1\n",
    "    elif isinstance(temperature_settings, (int, float)):\n",
    "        temperatures = [temperature_settings] * p  # 单个值应用到所有请求\n",
    "    elif isinstance(temperature_settings, (list, tuple)) and len(temperature_settings) == p:\n",
    "        temperatures = temperature_settings  # 使用提供的温度列表\n",
    "    else:\n",
    "        raise ValueError(\"temperature_settings should be a single value or a list of length p\")\n",
    "    \n",
    "    # 初始化聚合模型和编码器\n",
    "    aggregation_model = HierarchicalAggregationLayer(hidden_size=768, num_perspectives=p)\n",
    "    encoder_model, tokenizer = load_encoder_model()\n",
    "    \n",
    "    # 使用线程池并行处理多个，每个请求使用不同的temperature\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=p) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_perspective, \n",
    "                i, \n",
    "                metaprompt, \n",
    "                encoder_model, \n",
    "                tokenizer, \n",
    "                llm, \n",
    "                temperatures[i]\n",
    "            ) for i in range(p)\n",
    "        ]\n",
    "        results = [future.result() for future in futures]\n",
    "    \n",
    "    # 按索引排序确保顺序正确\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    encoded_responses = [enc for _, _, enc in results]  # 提取编码向量\n",
    "    response_texts = [resp for _, resp, _ in results]  # 提取回答文本\n",
    "    for idx, (text, temp) in enumerate(zip(response_texts, temperatures), start=1):\n",
    "        print(f\"第{idx}个(temperature={temp:.2f})：{text}\")\n",
    "        \n",
    "    if encoded_responses:\n",
    "        # 聚合多视角信息并获取权重\n",
    "        aggregated_output, weights = aggregation_model(encoded_responses)\n",
    "        \n",
    "        # 按权重排序视角\n",
    "        sorted_items = sorted([(i, f\"response_{i+1}\", weights[0, i].item()) for i in range(p)], \n",
    "                             key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # 获取topk视角\n",
    "        top_indices = torch.topk(weights[0], topk).indices\n",
    "        top_perspectives = [(f\"response_{idx+1}\", weights[0, idx].item(), response_texts[idx]) \n",
    "                           for idx in top_indices]\n",
    "        \n",
    "        # 构建最终标题（当前已注释掉）\n",
    "        final_title = \"\\n\".join(re.sub(r'【[^】]+】', '', content).strip() for _, _, content in top_perspectives)\n",
    "        \n",
    "        return {\n",
    "            # \"final_title\": final_title,\n",
    "            \"top_perspectives\": top_perspectives,\n",
    "            # \"temperature_settings\": temperatures,  # 返回使用的温度设置\n",
    "            # \"all_weights\": [(f\"response_{i+1}\", weights[0, i].item()) for i in range(p)]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    metaprompt = \"\"\"\n",
    "任务： 从给定的客服对话记录中提取关键信息，并生成一个结构化的 JSON 格式输出。\n",
    "\n",
    "要求：\n",
    "1. 提取以下字段：\n",
    "  order_number（从系统消息或用户反馈中查找办理业务订单号）\n",
    "  business_Number（用户要办理的手机号）\n",
    "  name（用户提供的姓名，区分客服的姓名，和用户的姓名）\n",
    "  contact_Phone（用户提供的手机号）\n",
    "  user_feedback_issue（用户的主要投诉或咨询内容，尽量详细，且要以客服的视角描述）\n",
    "  user_request（用户希望解决的问题或需求，尽量详细，且要以客服的视角描述）\n",
    "  cons_progress（工号xx开头的客服为用户查询了什么，和用户确认了什么，尽量详细）\n",
    "  cardType（判断用户咨询的业务类型号的卡，必须是这些门类：充值 权益包 流量包 业务办理 不确定）\n",
    "2. 确保 JSON 格式正确，字段值尽量从对话原文中提取\n",
    "3. 如果没有输出为空值！！！\n",
    "最终输出格式：\n",
    "{\n",
    "  \"order_number\": \"\",\n",
    "  \"business_Number\": \"\",\n",
    "  \"name\": \"\",\n",
    "  \"contact_Phone\": \"\",\n",
    "  \"user_feedback_issue\": \"\",\n",
    "  \"user_request\": \"\",\n",
    "  \"cons_progress\": \"\",\n",
    "  \"cardType\": \"\"\n",
    "}\n",
    "下面是要处理的客服对话片段：\n",
    "\n",
    "(系统消息)      2025-05-11 14:13:04\n",
    "正在为您接入人工服务，请稍等；您也可以发送【00】退出服务\n",
    "(系统消息)      2025-05-11 14:13:04\n",
    "客户IM号码（TYMY_H5dq250511024844208）已关联号码（TYMY_H515767962194）\n",
    "梁鑫一(95047)      2025-05-11 14:13:05\n",
    "您好，感谢您的耐心等待，系统已为您接入人工服务。中国电信95047号客服为您服务。\n",
    "(0)      2025-05-11 14:13:05\n",
    "【系统消息】15767962194,null,null ; 不可办理5G升级包\n",
    "(0)      2025-05-11 14:13:05\n",
    "人工[文本]\n",
    "(0)      2025-05-11 14:13:05\n",
    "【系统消息】亲，您可以#LinkIDSwitchToCSR马上召唤人工客服为您服务。<br/>以下是小知经常回答的问题哦：<br/>[1]购买号卡后找不到订单<br/>[2]我的卡有余额但无法使用<br/>[3]我想换个套餐有什么推荐吗<br/>[4]携号转网问题<br/>[5]我的卡提示被保护，停机了[文本]\n",
    "(0)      2025-05-11 14:13:05\n",
    "【客服请回复】请及时答复用户问题\n",
    "(0)      2025-05-11 14:13:27\n",
    "这个卡购买卡的30块不会作为预存话费的吗[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:13:49\n",
    "尊敬的用户您好！这里是中国电信网上营业厅人工客服，工号95047，请问您有什么问题需要帮助吗？我将尽力为您提供最优质的服务！\n",
    "梁鑫一(95047)      2025-05-11 14:13:53\n",
    "辛苦您方便提供一下收货号码或身份证号吗？\n",
    "(0)      2025-05-11 14:14:04\n",
    "15767962194[文本]\n",
    "(0)      2025-05-11 14:15:18\n",
    "我昨天号码卡到了，快递小哥开卡后一直没信号，我打电话你们客服，客服让我再充值30元，但是现在只有30块话费，正常来说不应该是60块话费吗？[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:15:30\n",
    "亲，正在为您积极查询中，预计需要1到3分钟，请您稍等。 （正在为您查询~!这句无需回复喔~）\n",
    "梁鑫一(95047)      2025-05-11 14:17:02\n",
    "15767962194未查询到信息，您是通过什么渠道购买的呢？方便提供订单编号吗？\n",
    "梁鑫一(95047)      2025-05-11 14:17:16\n",
    "抱歉亲亲查询错误\n",
    "(0)      2025-05-11 14:17:17\n",
    "你们这个小程序啊[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:17:19\n",
    "2025-05-08 21:25:59下单的这个吗？\n",
    "(0)      2025-05-11 14:17:23\n",
    "对啊[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:17:47\n",
    "亲，请您稍等不要离开呦~我现在为您查询，谢谢亲的配合与理解。\n",
    "梁鑫一(95047)      2025-05-11 14:18:01\n",
    "通用可用余额: 0专用余额: 30\n",
    "梁鑫一(95047)      2025-05-11 14:18:02\n",
    "您好，为了您能得到更专业的服务，您所咨询的问题需要转到号码归属（省）专席为您跟进（以上对话记录也会一同转接），转接期间请勿退出，如线路繁忙，可以联系号码归属省10000万号，同意转接回复1\n",
    "(0)      2025-05-11 14:18:38\n",
    "怎么回事？[文本]\n",
    "(0)      2025-05-11 14:18:48\n",
    "我就是问你怎么话费只有30块啊[文本]\n",
    "(0)      2025-05-11 14:19:05\n",
    "这个卡是买卡的30块不是作为预存话费的吗？[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:19:10\n",
    "话费是您订单内的30激活已充值\n",
    "(0)      2025-05-11 14:19:13\n",
    "听不懂话吗？[文本]\n",
    "(0)      2025-05-11 14:19:22\n",
    "那我买卡的30块呢[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:19:33\n",
    "这个就是买卡的亲亲\n",
    "梁鑫一(95047)      2025-05-11 14:19:40\n",
    "激活中要求您充值的这边查询不到\n",
    "梁鑫一(95047)      2025-05-11 14:19:41\n",
    "为您转接省内客服为您核实看看好吗？\n",
    "(0)      2025-05-11 14:19:57\n",
    "买卡的钱不会变成话费的意思是吗？[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:20:52\n",
    "会\n",
    "梁鑫一(95047)      2025-05-11 14:20:55\n",
    "已经到了亲亲\n",
    "(0)      2025-05-11 14:21:02\n",
    "并没有啊[文本]\n",
    "(0)      2025-05-11 14:21:15\n",
    "我现在的30块是后面充值的啊[文本]\n",
    "(0)      2025-05-11 14:21:24\n",
    "现在你们两边踢皮球还是怎么样[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:21:36\n",
    "亲，您说的问题这边为您记录反馈，请您提供一下能联系到您的手机号和您的姓名，给您带来不便请您谅解，我们会通过电话的方式告知您处理结果，请您保持电话畅通\n",
    "梁鑫一(95047)      2025-05-11 14:21:54\n",
    "您激活充值的30 账单麻烦截图\n",
    "(0)      2025-05-11 14:22:22\n",
    "SVU2OE1NIXhqeFMhUyFPTyFYO05IT1lqak5jeFlPbUNR1007-100-100-11-lnsy.png\n",
    "梁鑫一(95047)      2025-05-11 14:22:47\n",
    "亲亲稍等加载图片看下\n",
    "(0)      2025-05-11 14:22:55\n",
    "昨天充值的，赶紧看怎么回事啊，不然我就工信局投诉你们欺骗消费者了[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:24:45\n",
    "15767962194这个号码能联系到您吗？\n",
    "(0)      2025-05-11 14:25:29\n",
    "可以[文本]\n",
    "梁鑫一(95047)      2025-05-11 14:25:51\n",
    "您好，您反馈的问题，客服已反馈到相关部门，预计48小时内，我们的工作人员会使用4008开头的电话跟您15767962194的号码联系，请您保持电话畅通，感谢您的理解！\n",
    "梁鑫一(95047)      2025-05-11 14:27:44\n",
    "亲亲您还有其他需要帮助的吗？\n",
    "(系统消息)      2025-05-11 14:29:45\n",
    "请问您还在线吗？ 如随后2分钟仍未收到您的消息，本次会话将暂时结束；如您的问题已解决，可发送【00】结束本次会话。\n",
    "(系统消息)      2025-05-11 14:29:45\n",
    "用户2分钟未发言或回复消息，系统已向用户发送提示消息\n",
    "(系统消息)      2025-05-11 14:30:05\n",
    "【系统消息】用户主动结束了该会话\n",
    "\"\"\"\n",
    "    \n",
    "    # 手动设置每次并发的温度值\n",
    "    manual_temperatures = [0.2, 0.4, 0.6, 0.8, 1, 1.4,1.8,2]\n",
    "    # manual_temperatures = [0.2, 0.4, 0.6, 0.8, 1, 1.4, 2]\n",
    "    # manual_temperatures = [0.2, 0.5, 0.8, 1, 1.4, 2]\n",
    "    # manual_temperatures = [0.2, 0.6, 0.8, 1.4, 2]\n",
    "    # manual_temperatures = [0.2, 0.6, 1, 2]\n",
    "    # manual_temperatures = [0.2, 0.8, 2] # 客服总结\n",
    "    # manual_temperatures = [0.2, 2] # topk = 1\n",
    "\n",
    "    result = multi_perspective_analysis(\n",
    "        metaprompt, \n",
    "        p=len(manual_temperatures),  # 自动根据温度列表长度确定p值\n",
    "        topk=2, \n",
    "        llm=llm_qwen, \n",
    "        temperature_settings=manual_temperatures  # 传入手动设置的温度列表\n",
    "    )\n",
    "    \n",
    "    print(json.dumps(result, ensure_ascii=False, indent=2))  # 以JSON格式输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28443d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from openai import OpenAI\n",
    "\n",
    "class EnhancedAggregationLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    增强型聚合层，用于多视角响应的语义聚合\n",
    "    融合ParScale技术的注意力平滑机制，提升多视角分析的稳定性\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size=768, num_perspectives=3, parscale_smoothing=0.1):\n",
    "        \"\"\"\n",
    "        初始化聚合层\n",
    "        \n",
    "        Args:\n",
    "            hidden_size: 编码器输出的隐藏层维度，默认768（BERT-base配置）\n",
    "            num_perspectives: 多视角分析的视角数量，默认3个视角\n",
    "            parscale_smoothing: ParScale注意力平滑系数，防止极端权重，默认0.1\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_perspectives = num_perspectives\n",
    "        self.hidden_size = hidden_size\n",
    "        self.parscale_smoothing = parscale_smoothing\n",
    "        \n",
    "        # 定义聚合网络结构：线性变换+层归一化+激活函数+Dropout+输出权重\n",
    "        self.aggregate_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * num_perspectives, hidden_size),\n",
    "            torch.nn.LayerNorm(hidden_size),\n",
    "            torch.nn.SiLU(),  # 平滑激活函数，替代ReLU\n",
    "            torch.nn.Dropout(0.1),  # 防止过拟合\n",
    "            torch.nn.Linear(hidden_size, num_perspectives)\n",
    "        )\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)  # 权重归一化\n",
    "        \n",
    "    def forward(self, encoded_responses):\n",
    "        \"\"\"\n",
    "        前向传播：计算多视角响应的聚合权重和综合表示\n",
    "        \n",
    "        Args:\n",
    "            encoded_responses: 各视角响应的编码向量列表，形状为[p, h]\n",
    "        \n",
    "        Returns:\n",
    "            aggregated_output: 聚合后的综合向量，形状为[h]\n",
    "            weights: 各视角的注意力权重，形状为[1, p]\n",
    "        \"\"\"\n",
    "        stacked_responses = torch.stack(encoded_responses)  # 堆叠视角编码为[p, h]\n",
    "        concat_responses = stacked_responses.view(1, -1)  # 拼接为[1, p*h]用于特征提取\n",
    "        \n",
    "        raw_weights = self.aggregate_layer(concat_responses)  # 计算原始权重\n",
    "        weights = self.softmax(raw_weights)  # 权重归一化\n",
    "        \n",
    "        # 应用ParScale注意力平滑：防止某个视角权重过大\n",
    "        if self.parscale_smoothing > 0:\n",
    "            uniform_weight = 1.0 / self.num_perspectives\n",
    "            weights = weights * (1 - self.parscale_smoothing) + self.parscale_smoothing * uniform_weight\n",
    "        \n",
    "        # 加权求和生成综合表示\n",
    "        weighted_sum = torch.sum(stacked_responses * weights.t(), dim=0)  # [p, h] * [p, 1] 后求和\n",
    "        return weighted_sum, weights\n",
    "\n",
    "\n",
    "# 初始化OpenAI客户端，连接到本地Qwen模型服务\n",
    "client = OpenAI(api_key=\"0\", base_url=\"http://192.168.106.26:20000/v1\")\n",
    "\n",
    "def llm_qwen(prompt, model=\"Qwen3\", temperature=0.7, top_p=0.8, max_tokens=1024):\n",
    "    \"\"\"\n",
    "    调用Qwen模型API生成响应\n",
    "    \n",
    "    Args:\n",
    "        prompt: 输入提示词\n",
    "        model: 模型名称，默认Qwen3\n",
    "        temperature: 生成温度，控制随机性，默认0.7\n",
    "        top_p: 核采样参数，控制生成多样性，默认0.8\n",
    "        max_tokens: 最大生成长度，默认1024\n",
    "    \n",
    "    Returns:\n",
    "        模型生成的文本响应\n",
    "    \"\"\"\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def load_encoder_model():\n",
    "    \"\"\"\n",
    "    加载文本编码器模型（BERT-base）用于语义向量化\n",
    "    \n",
    "    Returns:\n",
    "        model: BERT模型实例\n",
    "        tokenizer: 对应的分词器\n",
    "    \"\"\"\n",
    "    from transformers import AutoModel, AutoTokenizer\n",
    "    model_name = \"/app/sda1/xiangyue/model/bert-base-chinese\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def encode_text(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    将文本转换为语义向量表示（使用BERT的[CLS]标记）\n",
    "    \n",
    "    Args:\n",
    "        text: 输入文本\n",
    "        model: BERT模型实例\n",
    "        tokenizer: 分词器实例\n",
    "    \n",
    "    Returns:\n",
    "        文本的语义编码向量，形状为[hidden_size]\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():  # 推理时关闭梯度计算\n",
    "        outputs = model(**inputs)\n",
    "    # 使用BERT的第一个标记（[CLS]）作为整体语义表示\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze(0)\n",
    "\n",
    "\n",
    "def process_perspective(index, question, encoder_model, tokenizer, llm_qwen):\n",
    "    \"\"\"\n",
    "    处理单个视角：生成响应并进行语义编码\n",
    "    \n",
    "    Args:\n",
    "        index: 视角索引（从0开始）\n",
    "        question: 分析问题\n",
    "        encoder_model: 编码器模型\n",
    "        tokenizer: 分词器\n",
    "        llm_qwen: LLM调用函数\n",
    "    \n",
    "    Returns:\n",
    "        index: 视角索引\n",
    "        response: 模型生成的响应文本\n",
    "        encoded_response: 响应的语义编码\n",
    "    \"\"\"\n",
    "    # 为每个视角添加标识，引导模型从不同角度思考\n",
    "    perspective_prompt = f\"【视角{index+1}】{question}\"\n",
    "    response = llm_qwen(perspective_prompt)  # 调用Qwen模型生成响应\n",
    "    encoded_response = encode_text(response, encoder_model, tokenizer)  # 编码响应文本\n",
    "    return index, response, encoded_response\n",
    "\n",
    "\n",
    "def multi_perspective_analysis(metaprompt, p=3, topk=1):\n",
    "    \"\"\"\n",
    "    多视角分析主函数：生成多个视角响应并聚合分析结果\n",
    "    \n",
    "    Args:\n",
    "        metaprompt: 元提示词（分析问题）\n",
    "        p: 生成的视角数量，默认3个\n",
    "        topk: 保留的关键视角数量，默认1个\n",
    "    \n",
    "    Returns:\n",
    "        包含聚合结果、关键视角和所有视角权重的字典\n",
    "    \"\"\"\n",
    "    # 初始化聚合模型与编码器\n",
    "    aggregation_model = EnhancedAggregationLayer(hidden_size=768, num_perspectives=p)\n",
    "    encoder_model, tokenizer = load_encoder_model()\n",
    "    \n",
    "    # 并行处理多个视角（使用线程池提高效率）\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=p) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_perspective, i, metaprompt, encoder_model, tokenizer, llm_qwen\n",
    "            )\n",
    "            for i in range(p)\n",
    "        ]\n",
    "        # 收集所有视角的处理结果\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "    # 按视角索引排序结果\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    # 提取响应文本和编码向量\n",
    "    responses = [(f\"response_{i+1}\", resp) for i, (_, resp, _) in enumerate(results)]\n",
    "    encoded_responses = [enc for _, _, enc in results]\n",
    "    response_texts = [resp for _, resp, _ in results]\n",
    "    \n",
    "    # 打印原始响应（调试和可视化）\n",
    "    print(\"=== 原始响应 ===\")\n",
    "    for i, (key, response) in enumerate(responses):\n",
    "        print(f\"{key}: {response}\")\n",
    "    \n",
    "    # 执行聚合逻辑（仅当有有效响应时）\n",
    "    if encoded_responses:\n",
    "        aggregated_output, weights = aggregation_model(encoded_responses)\n",
    "        \n",
    "        # 打印各视角的聚合权重\n",
    "        print(\"\\n=== 聚合权重 ===\")\n",
    "        for i, (key, _) in enumerate(responses):\n",
    "            print(f\"{key}: {weights[0, i].item():.4f}\")\n",
    "        \n",
    "        # 获取权重最高的topk个视角\n",
    "        top_weights, top_indices = torch.topk(weights[0], topk)\n",
    "        print(f\"\\n=== Top {topk} 视角 ===\")\n",
    "        top_perspectives = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            key = responses[idx][0]\n",
    "            weight = top_weights[i].item()\n",
    "            content = response_texts[idx]\n",
    "            print(f\"{key}: 权重={weight:.4f}\\n内容: {content}\")\n",
    "            top_perspectives.append((key, weight, content))\n",
    "        \n",
    "        # 生成最终聚合结果（合并关键视角内容）\n",
    "        final_title = \"\\n\".join(re.sub(r'【[^】]+】', '', content).strip() for _, _, content in top_perspectives)\n",
    "        print(\"\\n=== 最终聚合结果 ===\")\n",
    "        print(final_title)\n",
    "        \n",
    "        return {\n",
    "            \"final_title\": final_title,\n",
    "            \"top_perspectives\": top_perspectives,\n",
    "            \"all_weights\": [(responses[i][0], weights[0, i].item()) for i in range(p)]\n",
    "        }\n",
    "    else:\n",
    "        print(\"没有有效的回答可供聚合\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 示例元提示词（空提示用于测试基本功能）\n",
    "    metaprompt = \"\"\"\n",
    "/no_think\n",
    "\"\"\"\n",
    "    # 执行多视角分析（生成3个视角，保留1个关键视角）\n",
    "    result = multi_perspective_analysis(metaprompt, p=3, topk=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLaMA-Factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
